{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "__author__ = 'Oswaldo Ludwig'\n",
    "__version__ = '1.01'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)  # for reproducibility\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "import itertools\n",
    "import operator\n",
    "import pickle\n",
    "import numpy as np    \n",
    "from keras.preprocessing import sequence\n",
    "from scipy import sparse, io\n",
    "from numpy.random import permutation\n",
    "import re\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, RepeatVector, Bidirectional, Dropout, merge\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "# import theano.tensor as T\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of q & a 2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Mr. Speaker, I can imagine the conversation th...</td>\n",
       "      <td>Mr. Speaker, we are the ones who put in place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Mr. Speaker, Ms. Meilleur demonstrated that sh...</td>\n",
       "      <td>Mr. Speaker, after 10 years of petty politics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Mr. Speaker, in Quebec, the law is clear. A ba...</td>\n",
       "      <td>Mr. Speaker, we want to ensure that Canadian c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Mr. Speaker, I will now read a motion that the...</td>\n",
       "      <td>Mr. Speaker, we want to be very clear. It is v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Mr. Speaker, according to  \\lineBreak The ques...</td>\n",
       "      <td>Mr. Speaker, in the past 18 months, Canada has...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Q  \\\n",
       "1995  Mr. Speaker, I can imagine the conversation th...   \n",
       "1996  Mr. Speaker, Ms. Meilleur demonstrated that sh...   \n",
       "1997  Mr. Speaker, in Quebec, the law is clear. A ba...   \n",
       "1998  Mr. Speaker, I will now read a motion that the...   \n",
       "1999  Mr. Speaker, according to  \\lineBreak The ques...   \n",
       "\n",
       "                                                      A  \n",
       "1995  Mr. Speaker, we are the ones who put in place ...  \n",
       "1996  Mr. Speaker, after 10 years of petty politics ...  \n",
       "1997  Mr. Speaker, we want to ensure that Canadian c...  \n",
       "1998  Mr. Speaker, we want to be very clear. It is v...  \n",
       "1999  Mr. Speaker, in the past 18 months, Canada has...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_hansard  = pd.read_csv('../../minerva/data/hansard_full.csv')\n",
    "\n",
    "df_group = df_hansard.groupby('subjectOfBusinessId')\n",
    "\n",
    "# for i in range(20):\n",
    "#     print(i, df_hansard.iloc[i]['content'])\n",
    "#     print('-' * 50)\n",
    "\n",
    "q_a = []\n",
    "for i, index in df_group.groups.items():\n",
    "#     print(i, index)\n",
    "    # don't bother with odd pairs\n",
    "    if (len(index) % 2 != 0): \n",
    "        continue\n",
    "        \n",
    "#     print(list(index))\n",
    "    t = df_hansard.iloc[list(index)]['content'].values\n",
    "#     print(t)\n",
    "#     print(list(zip(t[::2], t[1::2])))\n",
    "    q_a.append(list(zip(t[::2], t[1::2])))\n",
    "\n",
    "q_a = [item for sublist in q_a for item in sublist]\n",
    "\n",
    "q_a = q_a[:2000]\n",
    "\n",
    "print('number of q & a', len(q_a))\n",
    "    \n",
    "df_q_a = pd.DataFrame(q_a)\n",
    "df_q_a.columns = ['Q', 'A']\n",
    "df_q_a.to_csv('data/q_a.csv')\n",
    "df_q_a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the context data...\n",
      "Reading the answer data...\n",
      "Tokenazing the answers...\n",
      "Mr. Speaker, I want to thank the member for Huron—Bruce for his commitment to our great veterans and their families.  \\lineBreak We are building on the successes of the privacy action plan to ensure that the private information of our veterans remains protected. That is why I present today the privacy action plan 2.0, which includes providing targeted training on privacy principles, streamlining consent forms and ensuring new initiatives are compliant with privacy requirements. \\lineBreak Our government is clear: we will not tolerate any privacy breach. \n",
      "['BOS', 'Mr.', 'Speaker,', 'I', 'want', 'to', 'thank', 'the', 'member', 'for', 'Huron—Bruce', 'for', 'his', 'commitment', 'to', 'our', 'great', 'veterans', 'and', 'their', 'families.', '\\\\lineBreak', 'We', 'are', 'building', 'on', 'the', 'successes', 'of', 'the', 'privacy', 'action', 'plan', 'to', 'ensure', 'that', 'the', 'private', 'information', 'of', 'our', 'veterans', 'remains', 'protected.', 'That', 'is', 'why', 'I', 'present', 'today', 'the', 'privacy', 'action', 'plan', '2.0,', 'which', 'includes', 'providing', 'targeted', 'training', 'on', 'privacy', 'principles,', 'streamlining', 'consent', 'forms', 'and', 'ensuring', 'new', 'initiatives', 'are', 'compliant', 'with', 'privacy', 'requirements.', '\\\\lineBreak', 'Our', 'government', 'is', 'clear:', 'we', 'will', 'not', 'tolerate', 'any', 'privacy', 'breach.', 'EOS']\n",
      "Mr. Speaker, our government believes any violation of our veterans' privacy is totally unacceptable. Over a year ago we took action and put in place a 10-point privacy action plan to ensure strict disciplinary measures for those who violate the law, while strengthening access, controls and monitoring. \\lineBreak Could the minister update the House on how our government has continued to enhance protection around privacy for Canadian veterans?\n",
      "['BOS', 'Mr.', 'Speaker,', 'our', 'government', 'believes', 'any', 'violation', 'of', 'our', \"veterans'\", 'privacy', 'is', 'totally', 'unacceptable.', 'Over', 'a', 'year', 'ago', 'we', 'took', 'action', 'and', 'put', 'in', 'place', 'a', '10-point', 'privacy', 'action', 'plan', 'to', 'ensure', 'strict', 'disciplinary', 'measures', 'for', 'those', 'who', 'violate', 'the', 'law,', 'while', 'strengthening', 'access,', 'controls', 'and', 'monitoring.', '\\\\lineBreak', 'Could', 'the', 'minister', 'update', 'the', 'House', 'on', 'how', 'our', 'government', 'has', 'continued', 'to', 'enhance', 'protection', 'around', 'privacy', 'for', 'Canadian', 'veterans?', 'EOS']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>paragraphs_a</th>\n",
       "      <th>paragraphs_b</th>\n",
       "      <th>Q_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Mr. Speaker, I can imagine the conversation th...</td>\n",
       "      <td>Mr. Speaker, we are the ones who put in place ...</td>\n",
       "      <td>BOS Mr. Speaker, we are the ones who put in pl...</td>\n",
       "      <td>BOS Mr. Speaker, I can imagine the conversatio...</td>\n",
       "      <td>BOS Mr. Speaker, we are the ones who put in pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Mr. Speaker, Ms. Meilleur demonstrated that sh...</td>\n",
       "      <td>Mr. Speaker, after 10 years of petty politics ...</td>\n",
       "      <td>BOS Mr. Speaker, after 10 years of petty polit...</td>\n",
       "      <td>BOS Mr. Speaker, Ms. Meilleur demonstrated tha...</td>\n",
       "      <td>BOS Mr. Speaker, after 10 years of petty polit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Mr. Speaker, in Quebec, the law is clear. A ba...</td>\n",
       "      <td>Mr. Speaker, we want to ensure that Canadian c...</td>\n",
       "      <td>BOS Mr. Speaker, we want to ensure that Canadi...</td>\n",
       "      <td>BOS Mr. Speaker, in Quebec, the law is clear. ...</td>\n",
       "      <td>BOS Mr. Speaker, we want to ensure that Canadi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Mr. Speaker, I will now read a motion that the...</td>\n",
       "      <td>Mr. Speaker, we want to be very clear. It is v...</td>\n",
       "      <td>BOS Mr. Speaker, we want to be very clear. It ...</td>\n",
       "      <td>BOS Mr. Speaker, I will now read a motion that...</td>\n",
       "      <td>BOS Mr. Speaker, we want to be very clear. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Mr. Speaker, according to  \\lineBreak The ques...</td>\n",
       "      <td>Mr. Speaker, in the past 18 months, Canada has...</td>\n",
       "      <td>BOS Mr. Speaker, in the past 18 months, Canada...</td>\n",
       "      <td>BOS Mr. Speaker, according to  \\lineBreak The ...</td>\n",
       "      <td>BOS Mr. Speaker, in the past 18 months, Canada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Q  \\\n",
       "1995  Mr. Speaker, I can imagine the conversation th...   \n",
       "1996  Mr. Speaker, Ms. Meilleur demonstrated that sh...   \n",
       "1997  Mr. Speaker, in Quebec, the law is clear. A ba...   \n",
       "1998  Mr. Speaker, I will now read a motion that the...   \n",
       "1999  Mr. Speaker, according to  \\lineBreak The ques...   \n",
       "\n",
       "                                                      A  \\\n",
       "1995  Mr. Speaker, we are the ones who put in place ...   \n",
       "1996  Mr. Speaker, after 10 years of petty politics ...   \n",
       "1997  Mr. Speaker, we want to ensure that Canadian c...   \n",
       "1998  Mr. Speaker, we want to be very clear. It is v...   \n",
       "1999  Mr. Speaker, in the past 18 months, Canada has...   \n",
       "\n",
       "                                           paragraphs_a  \\\n",
       "1995  BOS Mr. Speaker, we are the ones who put in pl...   \n",
       "1996  BOS Mr. Speaker, after 10 years of petty polit...   \n",
       "1997  BOS Mr. Speaker, we want to ensure that Canadi...   \n",
       "1998  BOS Mr. Speaker, we want to be very clear. It ...   \n",
       "1999  BOS Mr. Speaker, in the past 18 months, Canada...   \n",
       "\n",
       "                                           paragraphs_b  \\\n",
       "1995  BOS Mr. Speaker, I can imagine the conversatio...   \n",
       "1996  BOS Mr. Speaker, Ms. Meilleur demonstrated tha...   \n",
       "1997  BOS Mr. Speaker, in Quebec, the law is clear. ...   \n",
       "1998  BOS Mr. Speaker, I will now read a motion that...   \n",
       "1999  BOS Mr. Speaker, according to  \\lineBreak The ...   \n",
       "\n",
       "                                                    Q_A  \n",
       "1995  BOS Mr. Speaker, we are the ones who put in pl...  \n",
       "1996  BOS Mr. Speaker, after 10 years of petty polit...  \n",
       "1997  BOS Mr. Speaker, we want to ensure that Canadi...  \n",
       "1998  BOS Mr. Speaker, we want to be very clear. It ...  \n",
       "1999  BOS Mr. Speaker, in the past 18 months, Canada...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "questions_file = 'context'\n",
    "answers_file = 'answers'\n",
    "vocabulary_file = 'vocabulary_movie'\n",
    "padded_questions_file = 'Padded_context'\n",
    "padded_answers_file = 'Padded_answers'\n",
    "unknown_token = 'something'\n",
    "\n",
    "# vocabulary_size = 7000\n",
    "# max_features = vocabulary_size\n",
    "# maxlen_input = 50\n",
    "# maxlen_output = 50  # cut texts after this number of words\n",
    "\n",
    "print (\"Reading the context data...\")\n",
    "# q = open(questions_file, 'r')\n",
    "questions = df_q_a['Q'].values\n",
    "print (\"Reading the answer data...\")\n",
    "# a = open(answers_file, 'r')\n",
    "answers = df_q_a['A'].values\n",
    "\n",
    "all_q_a = answers + questions\n",
    "print (\"Tokenazing the answers...\")\n",
    "paragraphs_a =  answers #[p for p in answers.split('\\n')]\n",
    "paragraphs_b =  questions # all_q_a #[p for p in all.split('\\n')]\n",
    "paragraphs_a = ['BOS '+p+' EOS' for p in paragraphs_a]\n",
    "paragraphs_b = ['BOS '+p+' EOS' for p in paragraphs_b]\n",
    "\n",
    "# update DF\n",
    "df_q_a['paragraphs_a'] = paragraphs_a\n",
    "df_q_a['paragraphs_b'] = paragraphs_b\n",
    "df_q_a['Q_A'] = df_q_a[['paragraphs_a', 'paragraphs_b']].apply(lambda x: u' '.join(x), axis=1)\n",
    "\n",
    "\n",
    "# paragraphs_b = ' '.join(paragraphs_b)\n",
    "# tokenized_text = paragraphs_b.split()\n",
    "# paragraphs_q = questions #[p for p in questions.split('\\n') ]\n",
    "tokenized_answers = [p.split() for p in paragraphs_a]\n",
    "tokenized_questions = [p.split() for p in paragraphs_b]\n",
    "\n",
    "\n",
    "\n",
    "### Counting the word frequencies:\n",
    "##word_freq = nltk.FreqDist(itertools.chain(tokenized_text))\n",
    "##print (\"Found %d unique words tokens.\" % len(word_freq.items()))\n",
    "##\n",
    "### Getting the most common words and build index_to_word and word_to_index vectors:\n",
    "##vocab = word_freq.most_common(vocabulary_size-1)\n",
    "##\n",
    "### Saving vocabulary:\n",
    "##with open(vocabulary_file, 'w') as v:\n",
    "##    pickle.dump(vocab, v)\n",
    "\n",
    "print(answers[0])\n",
    "print(tokenized_answers[0])\n",
    "print(questions[0])\n",
    "print(tokenized_questions[0])\n",
    "\n",
    "df_q_a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "number of Q and A 2000\n",
      "Found 11495 unique tokens.\n",
      "Using vocabulary of size 10000.\n",
      "X.shape (2000, 100)\n",
      "Y.shape (2000, 100)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0   11   14   13   23   21 1447  134 3427    4   23 2180  742    6\n",
      " 1717  578  100   10  123  354    9  469  156    3  166    7  198   10\n",
      "  296  397  742  156   92    2  121 2473 6936  268   15   79   45 3085\n",
      "    1  297  189 2649  204 2650    3 1565    8  147    1   34  951    1\n",
      "   62   22   86   23   21   28 1787    2 1054  365  337  742   15   42\n",
      "  271   12]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_words = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 100 \n",
    "\n",
    "# print(u' '.join(str(v) for v in tokenized_questions))\n",
    "\n",
    "print('Loading data...')\n",
    "print('number of Q and A', len(df_q_a))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df_q_a[['Q_A']].apply(lambda x: u' '.join(x))) # fit on Q and A\n",
    "X = tokenizer.texts_to_sequences(u' '.join(v) for v in tokenized_questions)\n",
    "Y = tokenizer.texts_to_sequences(u' '.join(v) for v in tokenized_answers)\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print (\"Using vocabulary of size %d.\" % max_words)\n",
    "\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "Y = pad_sequences(Y, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "\n",
    "print(X[0])\n",
    "\n",
    "# Replacing all words not in our vocabulary with the unknown token:\n",
    "# for i, sent in enumerate(tokenized_answers):\n",
    "#     tokenized_answers[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
    "\n",
    "# for i, sent in enumerate(tokenized_questions):\n",
    "#     tokenized_questions[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
    "\n",
    "# Creating the training data:\n",
    "# X = np.asarray([[word_to_index[w] for w in sent] for sent in tokenized_questions])\n",
    "# Y = np.asarray([[word_to_index[w] for w in sent] for sent in tokenized_answers])\n",
    "\n",
    "# Q = sequence.pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# A = sequence.pad_sequences(Y, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# print(Q[0])\n",
    "# print(A[0])\n",
    "\n",
    "with open(padded_questions_file, 'wb') as q:\n",
    "    pickle.dump(X, q)\n",
    "    \n",
    "with open(padded_answers_file, 'wb') as a:\n",
    "    pickle.dump(Y, a)\n",
    "    \n",
    "    \n",
    "# Important.... print out the X and Y to find the EOS === here its 12\n",
    "EOS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 429693 word vectors.\n",
      "normalizing vectors\n"
     ]
    }
   ],
   "source": [
    "# **********************************************************************\n",
    "# Reading a pre-trained word embedding and addapting to our vocabulary:\n",
    "# **********************************************************************\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open( 'data/vectors.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('normalizing vectors')\n",
    "embedding_matrix = preprocessing.robust_scale(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model of the chatbot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "MAX_SEQUENCE_LENGTH 100\n",
      "max_words 10000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_context (InputLayer)      (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_answer (InputLayer)       (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    (None, 100, 100)     1149600     input_context[0][0]              \n",
      "                                                                 input_answer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encode_context (LSTM)           (None, 300)          481200      shared_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decode_answer (LSTM)            (None, 300)          481200      shared_embedding[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           encode_context[0][0]             \n",
      "                                                                 decode_answer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu_activation (Dense)         (None, 5000)         3005000     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax_activation (Dense)      (None, 10000)        50010000    relu_activation[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 55,127,000\n",
      "Trainable params: 55,127,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence_embedding_size = 300\n",
    "weights_file = 'nothing yet'\n",
    "\n",
    "def init_model():\n",
    "    print(type(X), type(Y)) \n",
    "\n",
    "    input_context = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input_context')\n",
    "    input_answer = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input_answer')\n",
    "\n",
    "    LSTM_encoder = LSTM(sentence_embedding_size, kernel_initializer='lecun_uniform', name='encode_context')\n",
    "    LSTM_decoder = LSTM(sentence_embedding_size, kernel_initializer='lecun_uniform', name='decode_answer')\n",
    "\n",
    "    if os.path.isfile(weights_file):\n",
    "        Shared_Embedding = Embedding(output_dim=EMBEDDING_DIM, input_dim=len(word_index) + 1, \n",
    "                                     input_length=MAX_SEQUENCE_LENGTH, name='shared_embedding')\n",
    "    else:\n",
    "    #     Shared_Embedding = Embedding(output_dim=EMBEDDING_DIM, input_dim=max_words, \n",
    "    #                                  weights=[embedding_matrix], input_length=maxlen_input)\n",
    "        Shared_Embedding = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n",
    "                                    weights=[embedding_matrix],\n",
    "                                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False, name='shared_embedding')\n",
    "\n",
    "    print('MAX_SEQUENCE_LENGTH', MAX_SEQUENCE_LENGTH)\n",
    "    print('max_words', max_words)\n",
    "\n",
    "    word_embedding_context = Shared_Embedding(input_context)\n",
    "    context_embedding = LSTM_encoder(word_embedding_context)\n",
    "\n",
    "    word_embedding_answer = Shared_Embedding(input_answer)\n",
    "    answer_embedding = LSTM_decoder(word_embedding_answer)\n",
    "\n",
    "    # merge_layer = Concatenate([context_embedding, answer_embedding], concat_axis=1)\n",
    "    merge_layer = Concatenate(axis=1)([context_embedding, answer_embedding])\n",
    "\n",
    "    out = Dense(int(max_words/2), activation='relu', name='relu_activation')(merge_layer)\n",
    "    out = Dense(max_words, activation='softmax', name='softmax_activation')(out)\n",
    "\n",
    "    model = Model(input=[input_context, input_answer], output = [out])\n",
    "\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.00005))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "#     if os.path.isfile(weights_file):\n",
    "#         model.load_weights(weights_file)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2000, 100)\n",
      "<class 'numpy.ndarray'>\n",
      "Number of exemples = 1500\n",
      "qt (500, 100) q (1499, 100)\n",
      "at (500, 100) a (1499, 100)\n",
      "step 300 round_exem 1500\n"
     ]
    }
   ],
   "source": [
    "# ************************************************************************\n",
    "# Loading the data:\n",
    "# ************************************************************************\n",
    "n_test = 500\n",
    "num_subsets = 5\n",
    "\n",
    "q = X #cPickle.load(open(questions_file, 'rb'))\n",
    "a = Y #cPickle.load(open(answers_file, 'rb'))\n",
    "\n",
    "print(type(q))\n",
    "print(a.shape)\n",
    "# n_exem, n_words = a.shape\n",
    "n_exem = a.shape[0]\n",
    "\n",
    "qt = q[0:n_test,:]\n",
    "at = a[0:n_test,:]\n",
    "q = q[n_test + 1:,:]\n",
    "a = a[n_test + 1:,:]\n",
    "\n",
    "print(type(q))\n",
    "\n",
    "print('Number of exemples = %d'%(n_exem - n_test))\n",
    "print('qt', qt.shape, 'q', q.shape)\n",
    "print('at', at.shape, 'a', a.shape)\n",
    "step = int(np.around((n_exem - n_test)/num_subsets))\n",
    "round_exem = int(step * num_subsets)\n",
    "print('step', step, 'round_exem', round_exem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 100\n",
    "BatchSize = 128  #  Check the capacity of your GPU\n",
    "Patience = 0\n",
    "dropout = .25\n",
    "n_test = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos order members know the standing orders require that we not interrupt other members when they are speaking linebreak the hon parliamentary secretary has the floor eos \n",
      "bos mr speaker the member for the member for the the member is the member for the linebreak we are the the member for the eos that is the the member for the the member for the eos that is the the member for the the member for the eos that is the the member for the the member for the eos that is the the member for the the member for the eos that is the the member for the the member for the eos that is the the member for the the member for the eos that is \n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocabulary = dict((v, k) for k, v in tokenizer.word_index.items())\n",
    "# vocabulary[1]\n",
    "\n",
    "BOS = 11\n",
    "\n",
    "def print_result(input_text):\n",
    "\n",
    "    ans_partial = np.zeros((1,MAX_SEQUENCE_LENGTH))\n",
    "    ans_partial[0, -1] = BOS  #  the index of the symbol BOS (begin of sentence)\n",
    "    for k in range(MAX_SEQUENCE_LENGTH - 1):\n",
    "        ye = model.predict([input_text, ans_partial])\n",
    "        mp = np.argmax(ye)\n",
    "        ans_partial[0, 0:-1] = ans_partial[0, 1:]\n",
    "        ans_partial[0, -1] = mp\n",
    "    \n",
    "#     print(ans_partial)\n",
    "    text = ''\n",
    "    for k in ans_partial[0]:\n",
    "        k = k.astype(int)\n",
    "        if k < (max_words-2):\n",
    "            w = vocabulary[k]\n",
    "            text = text + w + ' '\n",
    "    return(text)\n",
    "\n",
    "def print_index_to_vocab(input_index):\n",
    "    text = ''\n",
    "    input_index = filter(lambda a: a != 0, input_index)\n",
    "    for k in input_index:\n",
    "        text = text + vocabulary[k] + ' '\n",
    "    return(text)\n",
    "\n",
    "    \n",
    "\n",
    "# print(qt[0])\n",
    "# print(at[0])\n",
    "# print(q[0])\n",
    "# print(a[0])\n",
    "\n",
    "print(print_index_to_vocab(qt[41]))\n",
    "test_input = at[41:42]\n",
    "print(print_result(test_input))\n",
    "\n",
    "\n",
    "# train_input = q[41:42]\n",
    "# print(print_result(train_input)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 300\n",
      "n 0\n",
      "22009\n",
      "Training epoch: 0, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 302s 14ms/step - loss: 6.4447\n",
      "bos mr speaker the member the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member \n",
      "bos mr speaker the member the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 0, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 293s 14ms/step - loss: 5.6869\n",
      "bos mr speaker the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the \n",
      "bos mr speaker the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 0, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 291s 14ms/step - loss: 5.4658\n",
      "bos mr speaker the member to the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the \n",
      "bos mr speaker the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the member of the \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 0, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 294s 14ms/step - loss: 5.3115\n",
      "bos mr speaker i am the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member \n",
      "bos mr speaker i have been a government of the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 0, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 300s 14ms/step - loss: 5.2621\n",
      "bos mr speaker the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the \n",
      "bos mr speaker the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the \n",
      "n 0\n",
      "22009\n",
      "Training epoch: 1, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 302s 14ms/step - loss: 5.2405\n",
      "bos mr speaker i am pleased to the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for \n",
      "bos mr speaker i am pleased to the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 1, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 291s 14ms/step - loss: 5.0255\n",
      "bos mr speaker i would like to the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for \n",
      "bos mr speaker i would like to the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 1, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 291s 14ms/step - loss: 4.9639\n",
      "bos mr speaker i am very proud of the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos mr speaker i am proud of the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 1, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 297s 14ms/step - loss: 4.8684\n",
      "bos mr speaker i am very proud to the member for the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for the member for linebreak the member for linebreak the member for linebreak the member for the member for linebreak the member for linebreak the member for linebreak the member for the member for linebreak the member for linebreak the member for linebreak the member for the member for linebreak the member for linebreak the member for linebreak the member for the member for linebreak the member for linebreak the member \n",
      "bos mr speaker i am pleased to the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 1, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 310s 14ms/step - loss: 4.8894\n",
      "bos mr speaker the member for the member for linebreak we are working with the ndp of the ndp is a government that is a government of the ndp is a government that is a government of the ndp is a government that is a government of the ndp is a government that is a government of the ndp is a government that is a government of the ndp is a government that is a government of the ndp is a government that is a government of the ndp is a government that is a government of the ndp is \n",
      "bos mr speaker the government is a government of the ndp is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is a government that is \n",
      "n 0\n",
      "22009\n",
      "Training epoch: 2, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 304s 14ms/step - loss: 4.9201\n",
      "bos mr speaker i am pleased to the member for the member for linebreak we are going to the member for the member for linebreak we are going to the member for the member for linebreak we are going to the member for the member for linebreak we are going to the member for the member for linebreak we are going to the member for the member for linebreak we are going to the member for the member for linebreak we are going to the member for the member for linebreak we are going to the member for the member \n",
      "bos mr speaker i am pleased to the member opposite that the member opposite is the member for linebreak we are going to be the member for the member for linebreak we are going to be the member for the member for linebreak we are going to be the member for the member for linebreak we are going to be the member for the member for linebreak we are going to be the member for the member for linebreak we are going to be the member for the member for linebreak we are going to be the member for the \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 2, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 291s 14ms/step - loss: 4.7540\n",
      "bos mr speaker i am pleased to thank the member for linebreak the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the member for the \n",
      "bos mr speaker i am pleased to thank the member for linebreak the member for the member for the linebreak we are working with the ndp eos and we are going to be a that that is why we are going to be a very clear that the ndp is a very clear that the ndp is a very clear that the ndp is a very clear that the ndp is a very clear that the ndp is a very clear that the ndp is a very clear that the ndp is a very clear that the ndp is a \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 2, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 291s 14ms/step - loss: 4.7146\n",
      "bos mr speaker i am pleased to thank the member for linebreak we are going to do not not have a new canadian forces are the member for the member for linebreak we are going to do not not have a new canadian forces are the member for the member for linebreak we are going to do not not have a new canadian forces are the member for the member for linebreak we are going to do not not have a new canadian forces are the member for the member for linebreak we are going to do not not have \n",
      "bos mr speaker i am pleased to thank the member for linebreak we are going to do not have been a very important to be a of the house that is a very important to be a priority for the middle class and the canadian forces are working with the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces are the canadian forces \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 2, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 293s 14ms/step - loss: 4.6346\n",
      "bos mr speaker i am pleased to thank the member for linebreak we are working with the member for linebreak we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going \n",
      "bos mr speaker i am pleased to thank the member for linebreak we are working with the member for linebreak we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going to make sure that we are going \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 2, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 299s 14ms/step - loss: 4.6685\n",
      "bos mr speaker the member for the member for linebreak we are going to make sure that we are going to be a priority for the ndp eos and the member for the member for linebreak we are going to do not the ndp eos and the member for the member for linebreak we are going to do not the ndp eos and the member for the member for linebreak we are going to do not the ndp eos and the member for the member for linebreak we are going to do not the ndp eos and the member for \n",
      "bos mr speaker i am very pleased to be a very important to be the member for the ndp is a very important to be the member for the ndp is a very important to be the member for the ndp is a very important to be the member for the ndp is a very important to be the member for the ndp is a very important to be the member for the ndp is a very important to be the member for the ndp is a very important to be the member for the ndp is a very important \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 0\n",
      "22009\n",
      "Training epoch: 3, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 299s 14ms/step - loss: 4.7174\n",
      "bos mr speaker the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the \n",
      "bos mr speaker the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the member opposite is the member opposite that the \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 3, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 281s 13ms/step - loss: 4.5626\n",
      "bos mr speaker i am pleased to thank the member for linebreak we are going to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue to \n",
      "bos mr speaker i am pleased to thank the member for linebreak we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to do eos and we are going to \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 3, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 274s 13ms/step - loss: 4.5264\n",
      "bos mr speaker the member is a very important question linebreak we are going to do the ndp eos and the ndp is the ndp to the ndp eos the ndp is the ndp to the canadian forces and the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the \n",
      "bos mr speaker i am pleased to thank the member for linebreak we are going to do the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 3, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 276s 13ms/step - loss: 4.4567\n",
      "bos mr speaker i am pleased to thank the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak the member for linebreak \n",
      "bos mr speaker i am pleased to thank the member for linebreak the member opposite is the member for linebreak we are working with the member opposite to be a very important question linebreak we are working with the member for linebreak we are working with the member for linebreak we are working with the member opposite to be a very important question linebreak we are working with the member for linebreak we are working with the member for linebreak we are working with the member opposite to be a very important question linebreak we are working with the member \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 3, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 283s 13ms/step - loss: 4.4909\n",
      "bos mr speaker the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the \n",
      "bos mr speaker the government is committed to the canadian forces and the canadian forces are working with the provinces and territories to the canadian forces are the member for linebreak we are working with the provinces and territories to the canadian forces are the member for linebreak we are working with the provinces and territories to the canadian forces are the member for linebreak we are working with the provinces and territories to the canadian forces are the member for linebreak we are working with the provinces and territories to the canadian forces are the member for linebreak we \n",
      "n 0\n",
      "22009\n",
      "Training epoch: 4, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 284s 13ms/step - loss: 4.5467\n",
      "bos mr speaker i am pleased to the member opposite that the member opposite is the member for linebreak we are working with the provinces and territories to the member for linebreak we are working with the provinces and territories to the member for linebreak we are working with the provinces and territories to the member for linebreak we are working with the provinces and territories to the member for linebreak we are working with the provinces and territories to the member for linebreak we are working with the provinces and territories to the member for linebreak we are working \n",
      "bos mr speaker i am pleased to thank the member for linebreak we are working with the provinces and territories to the provinces and territories to the member for linebreak we are working with the provinces and territories to the provinces and territories to the member for linebreak we are working with the provinces and territories to the provinces and territories to the member for linebreak we are working with the provinces and territories to the provinces and territories to the member for linebreak we are working with the provinces and territories to the provinces and territories to the member \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 4, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 275s 13ms/step - loss: 4.3938\n",
      "bos mr speaker i am pleased to thank the member for the member for the linebreak we are going to do the eos of the ndp has been the ndp to be the ndp and the ndp members are the ndp to be the ndp and the ndp members are the eos of the ndp and the ndp members are the ndp to do not have a very clear we are going to do eos and we will continue to do eos and we will continue to do eos and we will continue to do eos and we will continue \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos mr speaker i am pleased to thank the member for the member opposite that the ndp has been the member opposite that the ndp has been the ndp members are the member to be the member for the eos of the ndp has been a very clear that the ndp has been the ndp to be the ndp and the ndp members are the of the ndp and the ndp members are the of the ndp and the ndp members are the of the ndp and the ndp members are the of the ndp and the ndp members are \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 4, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 273s 13ms/step - loss: 4.3676\n",
      "bos mr speaker i am pleased to the member that the ndp has been a very clear that we are going to do eos and we have been working with the provinces and territories and we are working with the provinces and territories and we are going to do eos and we have been working with the provinces and territories and we are going to do eos and we have been working with the provinces and territories and we are working with the provinces and territories and we are going to do eos and we have been working with the \n",
      "bos mr speaker i am pleased to the member opposite that the ndp has been a very clear in the house and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian forces and the canadian forces are the canadian \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 4, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 276s 13ms/step - loss: 4.2916\n",
      "bos mr speaker i am pleased to thank the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak \n",
      "bos mr speaker i am pleased to thank the member for linebreak i am very proud of the house that the ndp has been working with the provinces and territories to the same time we are going to do eos and we are going to do eos eos and we are going to do eos and we are going to do eos eos and we are going to do eos and we are going to do eos eos and we are going to do eos and we are going to do eos eos and we are going to do eos \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 4, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 283s 13ms/step - loss: 4.3282\n",
      "bos mr speaker the member opposite is the member for linebreak we are working with the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to the provinces and territories to \n",
      "bos mr speaker i am pleased to thank the member for linebreak the member opposite is the member for linebreak we are working with the provinces and territories to the canadian forces will be the same time to ensure that we are working with the provinces and territories to the canadian forces will be the same time to ensure that we are working with the provinces and territories to the canadian forces will be the same time to ensure that we are working with the provinces and territories to the canadian forces will be the same time to ensure that \n",
      "n 0\n",
      "22009\n",
      "Training epoch: 5, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 284s 13ms/step - loss: 4.3884\n",
      "bos mr speaker i am pleased to thank the member for linebreak the member opposite is the member for linebreak we are working with the provinces and territories to the house that the ndp members are the member opposite is the member for linebreak we are working with the provinces and territories to the house that the ndp members are the member opposite is the member for linebreak we are working with the provinces and territories to the house that the ndp members are the member opposite is the member for linebreak we are working with the provinces and territories \n",
      "bos mr speaker i am pleased to thank the member for linebreak the member opposite is the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 5, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 275s 13ms/step - loss: 4.2333\n",
      "bos mr speaker i am pleased to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member \n",
      "bos mr speaker i am pleased to thank the member for linebreak i would like to thank the member for linebreak i have been very clear that the ndp has been to the ndp members opposite and the ndp members are going to be a very important question linebreak we are working with the provinces and the provinces and territories to the canadian forces and the ndp members are going to be a very clear we are going to be a very clear that the ndp has been to the ndp members opposite that the ndp has been very clear \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 5, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 274s 13ms/step - loss: 4.2059\n",
      "bos mr speaker i am pleased to the member opposite that the ndp has been the ndp members are not the member for linebreak the ndp has been the member for linebreak the member knows that the ndp has been the member to the member opposite would be to the member that the ndp has been the ndp members are not the member for linebreak the ndp has been the member for linebreak the member knows that the ndp has been the member to the member opposite would be to the member that the ndp has been the ndp members \n",
      "bos mr speaker i am pleased to the member opposite that the member is the member opposite is the member for linebreak we have been the member opposite is the member for linebreak we have been the member opposite is the member for linebreak we have been the member opposite is the member for linebreak we have been the member opposite is the member for linebreak we have been the member opposite is the member for linebreak we have been the member opposite is the member for linebreak we have been the member opposite is the member for linebreak we \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 5, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 276s 13ms/step - loss: 4.1160\n",
      "bos mr speaker the member opposite is to the member for linebreak the member opposite has to the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos mr speaker i am pleased to thank the member for linebreak the member opposite has been to the member opposite has been to the member opposite is to the same time we are going to make sure that we have the same time to ensure that we are going to make sure that we have the same time to ensure that we are going to make sure that we have the same time to ensure that we are going to make sure that we have the same time to ensure that we are going to make sure that we \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 5, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 283s 13ms/step - loss: 4.1569\n",
      "bos mr speaker the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the member opposite is the member for linebreak the \n",
      "bos mr speaker i am pleased to thank the member for linebreak the member opposite is the member opposite to be the member opposite is the member opposite to be the member opposite is the member opposite to be the same time we are working with the provinces and territories to ensure that we are working with the provinces and territories to ensure that we are working with the provinces and territories to ensure that we are working with the provinces and territories to ensure that we are working with the provinces and territories to ensure that we are working \n",
      "n 0\n",
      "22009\n",
      "Training epoch: 6, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 284s 13ms/step - loss: 4.2185\n",
      "bos mr speaker i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member \n",
      "bos mr speaker i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 6, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 276s 13ms/step - loss: 4.0717\n",
      "bos mr speaker i am pleased to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member \n",
      "bos mr speaker i am pleased to thank the member for linebreak i have been clear about the ndp and i have been to the member opposite that was not a very good question linebreak i have been clear about the ndp to do so they need to do so they need to do eos eos and we will continue to work with the provinces and will be the of the environment eos and will be the of the environment and will be the best of the economy eos eos and we will continue to work with the provinces and \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 6, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 274s 13ms/step - loss: 4.0350\n",
      "bos mr speaker i am pleased to thank the member for linebreak i would like to thank the member for linebreak we are working with the provinces and territories to ensure that we are going to do so that we have been very clear that we have been very clear that we have been very clear that we have been very clear that we have been very clear that we have been very clear that we have been very clear that we have been very clear that we have been very clear that we have been very clear that we \n",
      "bos mr speaker i am pleased to thank the member for linebreak i have been clear that the ndp has been the best to the canadian forces of the canadian forces and the canadian forces of the canadian forces and all of the canadian forces will continue to do so eos and we are going to do so eos eos and we are going to do so eos and we are working with the provinces and territories to ensure that we are going to do so eos and we are working with the provinces and territories to ensure that we \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 6, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 277s 13ms/step - loss: 3.9463\n",
      "bos mr speaker the member opposite has been to the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the \n",
      "bos mr speaker i am pleased to thank the member for his question linebreak i am very proud of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 6, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 284s 13ms/step - loss: 3.9937\n",
      "bos mr speaker the member opposite is the member for linebreak the ndp members of the house that the ndp has not only for the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian armed forces and the \n",
      "bos mr speaker i am pleased to thank the member for linebreak the government of the canadian armed forces have been in the past two years to the canadian armed forces have been to the canadian armed forces and all of the canadian armed forces have been in the past two years to the canadian armed forces have been to the canadian armed forces and all of the canadian armed forces have been in the past two years to the canadian armed forces have been to the canadian armed forces and all of the canadian armed forces have been in \n",
      "n 0\n",
      "22009\n",
      "Training epoch: 7, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 290s 13ms/step - loss: 4.0670\n",
      "bos mr speaker i am pleased to thank the member for linebreak i am very proud to announce that the canadian armed forces of the united states of the house and the eos of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of \n",
      "bos mr speaker i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member for linebreak i am pleased to thank the member \n",
      "n 300\n",
      "21352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 7, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 290s 14ms/step - loss: 3.9126\n",
      "bos mr speaker i am pleased to thank the member for linebreak the ndp members know that the ndp has been the ndp members are not the eos to the ndp members have been very clear that the ndp has been the ndp members are not the eos to the ndp members have been very clear that the ndp has been the ndp members are not the eos to the ndp members have been very clear that the ndp has been the ndp members are not the eos to the ndp members have been very clear that the ndp has \n",
      "bos mr speaker i am pleased to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member for linebreak i would like to thank the member \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 7, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 287s 14ms/step - loss: 3.8775\n",
      "bos mr speaker the member knows that the ndp voted against that they need to do the best way to the canadian armed forces and the canadian armed forces and the canadian armed forces and the canadian forces who are the ndp to do the ndp to do the eos of the house of the canadian armed forces and the canadian armed forces of the house to make sure that we have a new energy industry across the country and the canadian armed forces of the house to make sure that we have a new energy industry across the country \n",
      "bos mr speaker i thank my colleague for the question linebreak i am very proud of the house of the canadian forces of canada and the canadian forces of the canadian forces of the canadian forces of the canadian forces who are going to take action to ensure that we are going to make sure that we have been working with our partners to make sure that we are working with our partners to make sure that we are working with our partners to make sure that we are working with our partners to make sure that we are working \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 7, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 289s 14ms/step - loss: 3.7887\n",
      "bos mr speaker the government of the house of the house of the house of the house and the ndp members are the ndp to the eos and the ndp to make sure that we have to make sure that we have the same time to make sure that we have a national interest and have made a new interest and as all canadians can be able to make sure that we can make sure that we have the same time to make sure that we are doing eos and the canadian armed forces of the house to make sure \n",
      "bos mr speaker i am government to my colleague from the same rules are making sure that we are working with our partners to make sure that we are making sure we have the national interest and all canadians are going to make sure we have a national interest and all canadians are going to make sure we have a national interest and all canadians are going to make sure we have a national interest and all canadians are going to make sure we have a national interest and all canadians are going to make sure we have a national \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 7, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 296s 14ms/step - loss: 3.8350\n",
      "bos mr speaker the ndp not understand the that of the ndp has not only to the eos of the the linebreak the ndp does not not understand the the linebreak the ndp does not not understand the the linebreak the ndp does not not understand the the linebreak the ndp does not not understand the the linebreak the ndp does not not understand the the linebreak the ndp does not not understand the the linebreak the ndp does not not understand the the linebreak the ndp does not not understand the the linebreak the ndp does not not understand \n",
      "bos mr speaker i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the house i am very proud of the \n",
      "n 0\n",
      "22009\n",
      "Training epoch: 8, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 298s 14ms/step - loss: 3.8865\n",
      "bos mr speaker i am very pleased to announce the house of the united states they have the united states they have the to the house and i look forward to the house from the house to ensure that the united states they need to the united states they need to the the united states they need to the the united states they need to the the united states they need to the the united states they need to the the united states they need to the the united states they need to the the united states they need to \n",
      "bos mr speaker i am pleased to thank the member for linebreak i am very proud to announce that there are no of the united states they have been to the best way to ensure that they are not to ensure they are not to the united states they are not to the eos and to ensure that they are not to the united states but they are to the united states they need to the to the united states they need to the the united states they need to the the united states they need to the the united \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 8, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 289s 14ms/step - loss: 3.6990\n",
      "bos mr speaker i am pleased to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon \n",
      "bos mr speaker i am pleased to thank the hon member for his question linebreak i am very proud of the house i look forward to working with the provinces and will continue to work with our partners to ensure that we have a number of canadian workers and their families eos and we will continue to work with our partners to ensure that we have a good quality jobs across canada linebreak i am very proud of the house to ensure that we have the best way to ensure that all canadians can be able to invest in the \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 8, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 287s 14ms/step - loss: 3.6633\n",
      "bos mr speaker i am pleased to remind the house that the ndp members can be there to be there to be there to be there to be there are no to the opposition members have the ndp to do so that they can do so eos to the canadian armed forces of this to do so eos and we will continue to work with our allies to ensure that the canadian armed forces will be the best to protect our veterans across the country eos to the the member opposite to stand up and the opposition members have a \n",
      "bos mr speaker i am pleased to remind the member that he has been very clear that we have been the best to address these issues i am pleased to remind the member that he is committed to ensuring that all canadians can help them the people who need them eos eos and we will continue to work with our allies to ensure that our veterans were there to help them them the people who need them eos eos and we will continue to work with our allies to ensure that our veterans were there to help them them the \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 8, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 289s 14ms/step - loss: 3.5841\n",
      "bos mr speaker the member opposite was not to the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the house of the \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos mr speaker i am pleased to thank my colleague for his own question linebreak i am very pleased to thank the member for linebreak i am very pleased to thank the member for linebreak i am very pleased to thank the member for linebreak i am very pleased to thank the member for linebreak i am very pleased to thank the member for linebreak i am very pleased to thank the member for linebreak i am very pleased to thank the member for linebreak i am very pleased to thank the member for linebreak i am very pleased to \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 8, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      "21949/21949 [==============================] - 296s 13ms/step - loss: 3.6137\n",
      "bos mr speaker i am very pleased to be very clear that the ndp did not understand what there were not just as the ndp members are not working with indigenous peoples linebreak we have done a strong way to ensure that we have the best way to ensure that all of the canadian armed forces have the best way to ensure that they are not working with our partners to ensure that we have the best way to ensure that all of the canadian armed forces have the best way to ensure that they are not working with our \n",
      "bos mr speaker i am very pleased to be clear that he has been working with the provinces and territories to ensure that we have the best way to ensure that all of the canadian armed forces of canada and the canadian armed forces of our commitment to ensure they need to the canadian armed forces of our commitment to ensure they need to the canadian armed forces of our commitment to ensure they need to the canadian armed forces of our commitment to ensure they need to the canadian armed forces of our commitment to ensure they need to \n",
      "n 0\n",
      "22009\n",
      "Training epoch: 9, training examples: 0 - 300\n",
      "Epoch 1/1\n",
      "22009/22009 [==============================] - 297s 13ms/step - loss: 3.6730\n",
      "bos mr speaker i am very pleased to announce that the ndp does not understand what there is no longer not be there linebreak i will continue to work with the provinces to ensure that all canadians are to the best way to support them eos and the canadian public servants but we will continue to work with the united states to ensure that all the united states they will not to the house to support them eos and the canadian public servants but we will continue to work with the united states to ensure that all the united states \n",
      "bos mr speaker i am pleased to say that there is no one of the rcmp including its own the united states linebreak i am very proud to ensure that all canadians are not to support them linebreak i am very proud to announce that all canadians were made by the best way to ensure that all canadians can use of these measures linebreak i am pleased to say that there is no one of the best way to support the environment including the canadian armed forces of these issues and to ensure that all canadians can help them get \n",
      "n 300\n",
      "21352\n",
      "Training epoch: 9, training examples: 300 - 600\n",
      "Epoch 1/1\n",
      "21352/21352 [==============================] - 288s 14ms/step - loss: 3.4992\n",
      "bos mr speaker i would like to thank the hon member for his question linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank the hon member for linebreak i would like to thank \n",
      "bos mr speaker i am very proud of the question linebreak i would like to thank the hon member for his own question linebreak i would like to thank the hon member for his own question linebreak i would like to thank the hon member for his own question linebreak i would like to thank the hon member for his own question linebreak i would like to thank the hon member for his own question linebreak i would like to thank the hon member for his own question linebreak i would like to thank the hon member for his own \n",
      "n 600\n",
      "21208\n",
      "Training epoch: 9, training examples: 600 - 900\n",
      "Epoch 1/1\n",
      "21208/21208 [==============================] - 287s 14ms/step - loss: 3.4971\n",
      "bos mr speaker the member opposite would like to remind them that we have had a strong mandate to make sure that we do not want them to do so eos to the work that we have to do so eos to the canadian armed forces of this side of the house i am very proud of the canadian armed forces and all canadians to come forward to protect them and their families they need to do so eos to the provinces and territories from our allies to protect our justice system it is it to it eos to the \n",
      "bos mr speaker i want to thank the member for his question linebreak i want to thank the member for his question linebreak i want to thank the member for his question linebreak i want to thank the member for his question linebreak i want to thank the member for his question linebreak i want to thank the member for his question linebreak i want to thank the member for his question linebreak i want to thank the member for his question linebreak i want to thank the member for his question linebreak i want to thank the member for \n",
      "n 900\n",
      "21397\n",
      "Training epoch: 9, training examples: 900 - 1200\n",
      "Epoch 1/1\n",
      "21397/21397 [==============================] - 290s 14ms/step - loss: 3.4013\n",
      "bos mr speaker the hon member to his own question linebreak the hon member to the house of the house of the law eos to the issue of the united states we have the to the united states to the united states we have the to the united states to the united states we have the to the united states to the united states eos to the the united states the united states to the united states we have the to the united states to the united states we have the to the united states to the united states eos \n",
      "bos mr speaker i am pleased to announce that canada has been in partnership with indigenous communities to ensure that our government has done it is making sure that canadians get their own trade linebreak i am very pleased to ensure that all canadians are safe eos to the trade agreement our government has made it to ensure that all canadians can create jobs and economic growth and more work to ensure our government is committed to ensuring that canadians get their own what they are going to do eos and we will continue to work with all canadians to \n",
      "n 1200\n",
      "21949\n",
      "Training epoch: 9, training examples: 1200 - 1500\n",
      "Epoch 1/1\n",
      " 4224/21949 [====>.........................] - ETA: 4:05 - loss: 3.4958"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a8bb0e364e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training epoch: %d, training examples: %d - %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# *************************************************************************\n",
    "# Bot training:\n",
    "# *************************************************************************\n",
    "print(round_exem, step)\n",
    "\n",
    "x = range(0,Epochs) \n",
    "valid_loss = np.zeros(Epochs)\n",
    "train_loss = np.zeros(Epochs)\n",
    "for m in range(Epochs):\n",
    "    \n",
    "    # Loop over training batches due to memory constraints:\n",
    "    for n in range(0,round_exem,step):\n",
    "        print('n', n)\n",
    "        \n",
    "        q2 = q[n:n+step]\n",
    "        s = q2.shape\n",
    "        count = 0\n",
    "        for i, sent in enumerate(a[n:n+step]):\n",
    "            l = np.where(sent==EOS)  #  the position od the symbol EOS\n",
    "            limit = l[0][0]\n",
    "            count += limit + 1\n",
    "            \n",
    "        print(count)\n",
    "        Q = np.zeros((count,MAX_SEQUENCE_LENGTH))\n",
    "        A = np.zeros((count,MAX_SEQUENCE_LENGTH))\n",
    "        Y = np.zeros((count,max_words))\n",
    "        \n",
    "        # Loop over the training examples:\n",
    "        count = 0\n",
    "        for i, sent in enumerate(a[n:n+step]):\n",
    "            ans_partial = np.zeros((1,MAX_SEQUENCE_LENGTH))\n",
    "            \n",
    "            # Loop over the positions of the current target output (the current output sequence):\n",
    "            l = np.where(sent==EOS)  #  the position of the symbol EOS\n",
    "            limit = l[0][0]\n",
    "\n",
    "            for k in range(1,limit+1):\n",
    "                # Mapping the target output (the next output word) for one-hot codding:\n",
    "                y = np.zeros((1, max_words))\n",
    "                y[0, sent[k]] = 1\n",
    "\n",
    "                # preparing the partial answer to input:\n",
    "\n",
    "                ans_partial[0,-k:] = sent[0:k]\n",
    "\n",
    "                # training the model for one epoch using teacher forcing:\n",
    "                \n",
    "                Q[count, :] = q2[i:i+1] \n",
    "                A[count, :] = ans_partial \n",
    "                Y[count, :] = y\n",
    "                count += 1\n",
    "                \n",
    "        print('Training epoch: %d, training examples: %d - %d'%(m,n, n + step))\n",
    "        model.fit([Q, A], Y, batch_size=BatchSize, epochs=1, verbose=1)\n",
    "         \n",
    "        test_input = qt[41:42]\n",
    "        print(print_result(test_input))\n",
    "        train_input = q[41:42]\n",
    "        print(print_result(train_input))        \n",
    "        \n",
    "    model.save_weights(weights_file, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
