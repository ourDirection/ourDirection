{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "__author__ = 'Oswaldo Ludwig'\n",
    "__version__ = '1.01'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)  # for reproducibility\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "import itertools\n",
    "import operator\n",
    "import pickle\n",
    "import numpy as np    \n",
    "from keras.preprocessing import sequence\n",
    "from scipy import sparse, io\n",
    "from numpy.random import permutation\n",
    "import re\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, RepeatVector, Bidirectional, Dropout, merge\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "# import theano.tensor as T\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of q & a 17431\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17426</th>\n",
       "      <td>Order, please. Usually I can at least hear the...</td>\n",
       "      <td>Mr. Speaker, we have seen real improvements ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17427</th>\n",
       "      <td>Mr. Speaker, today we should be celebrating Ca...</td>\n",
       "      <td>Mr. Speaker, I assure my hon. colleague that w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17428</th>\n",
       "      <td>Mr. Speaker, the  \\lineBreak Recent changes to...</td>\n",
       "      <td>Mr. Speaker, we are extremely concerned and di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17429</th>\n",
       "      <td>Mr. Speaker, let us talk about the TPPCPTPTPP,...</td>\n",
       "      <td>Mr. Speaker, we have been clear. We continue t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17430</th>\n",
       "      <td>Mr. Speaker, the trans-Pacific partnership is ...</td>\n",
       "      <td>Mr. Speaker, as the member has said, this is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Q  \\\n",
       "17426  Order, please. Usually I can at least hear the...   \n",
       "17427  Mr. Speaker, today we should be celebrating Ca...   \n",
       "17428  Mr. Speaker, the  \\lineBreak Recent changes to...   \n",
       "17429  Mr. Speaker, let us talk about the TPPCPTPTPP,...   \n",
       "17430  Mr. Speaker, the trans-Pacific partnership is ...   \n",
       "\n",
       "                                                       A  \n",
       "17426  Mr. Speaker, we have seen real improvements ov...  \n",
       "17427  Mr. Speaker, I assure my hon. colleague that w...  \n",
       "17428  Mr. Speaker, we are extremely concerned and di...  \n",
       "17429  Mr. Speaker, we have been clear. We continue t...  \n",
       "17430  Mr. Speaker, as the member has said, this is a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_hansard  = pd.read_csv('../../minerva/data/hansard_full.csv')\n",
    "\n",
    "df_group = df_hansard.groupby('subjectOfBusinessId')\n",
    "\n",
    "# for i in range(20):\n",
    "#     print(i, df_hansard.iloc[i]['content'])\n",
    "#     print('-' * 50)\n",
    "\n",
    "q_a = []\n",
    "for i, index in df_group.groups.items():\n",
    "#     print(i, index)\n",
    "    # don't bother with odd pairs\n",
    "    if (len(index) % 2 != 0): \n",
    "        continue\n",
    "        \n",
    "#     print(list(index))\n",
    "    t = df_hansard.iloc[list(index)]['content'].values\n",
    "#     print(t)\n",
    "#     print(list(zip(t[::2], t[1::2])))\n",
    "    q_a.append(list(zip(t[::2], t[1::2])))\n",
    "\n",
    "q_a = [item for sublist in q_a for item in sublist]\n",
    "\n",
    "print('number of q & a', len(q_a))\n",
    "    \n",
    "df_q_a = pd.DataFrame(q_a)\n",
    "df_q_a.columns = ['Q', 'A']\n",
    "df_q_a.to_csv('data/q_a.csv')\n",
    "df_q_a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the context data...\n",
      "Reading the answer data...\n",
      "Tokenazing the answers...\n",
      "Mr. Speaker, I would like to congratulate the new Leader of the Opposition. His party was very successful in the recent election, and we can see the results of that here today. In the throne speech, we repeated the promises we made to voters during the election. The result is clear: we now have a stable majority Conservative government.\n",
      "['BOS', 'Mr.', 'Speaker,', 'I', 'would', 'like', 'to', 'congratulate', 'the', 'new', 'Leader', 'of', 'the', 'Opposition.', 'His', 'party', 'was', 'very', 'successful', 'in', 'the', 'recent', 'election,', 'and', 'we', 'can', 'see', 'the', 'results', 'of', 'that', 'here', 'today.', 'In', 'the', 'throne', 'speech,', 'we', 'repeated', 'the', 'promises', 'we', 'made', 'to', 'voters', 'during', 'the', 'election.', 'The', 'result', 'is', 'clear:', 'we', 'now', 'have', 'a', 'stable', 'majority', 'Conservative', 'government.', 'EOS']\n",
      "Mr. Speaker, I would like to begin by congratulating the  \\lineBreak Where is the government's desire to work with others?\n",
      "['BOS', 'Mr.', 'Speaker,', 'I', 'would', 'like', 'to', 'begin', 'by', 'congratulating', 'the', '\\\\lineBreak', 'Where', 'is', 'the', \"government's\", 'desire', 'to', 'work', 'with', 'others?', 'EOS']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>paragraphs_a</th>\n",
       "      <th>paragraphs_b</th>\n",
       "      <th>Q_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17426</th>\n",
       "      <td>Order, please. Usually I can at least hear the...</td>\n",
       "      <td>Mr. Speaker, we have seen real improvements ov...</td>\n",
       "      <td>BOS Mr. Speaker, we have seen real improvement...</td>\n",
       "      <td>BOS Order, please. Usually I can at least hear...</td>\n",
       "      <td>BOS Mr. Speaker, we have seen real improvement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17427</th>\n",
       "      <td>Mr. Speaker, today we should be celebrating Ca...</td>\n",
       "      <td>Mr. Speaker, I assure my hon. colleague that w...</td>\n",
       "      <td>BOS Mr. Speaker, I assure my hon. colleague th...</td>\n",
       "      <td>BOS Mr. Speaker, today we should be celebratin...</td>\n",
       "      <td>BOS Mr. Speaker, I assure my hon. colleague th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17428</th>\n",
       "      <td>Mr. Speaker, the  \\lineBreak Recent changes to...</td>\n",
       "      <td>Mr. Speaker, we are extremely concerned and di...</td>\n",
       "      <td>BOS Mr. Speaker, we are extremely concerned an...</td>\n",
       "      <td>BOS Mr. Speaker, the  \\lineBreak Recent change...</td>\n",
       "      <td>BOS Mr. Speaker, we are extremely concerned an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17429</th>\n",
       "      <td>Mr. Speaker, let us talk about the TPPCPTPTPP,...</td>\n",
       "      <td>Mr. Speaker, we have been clear. We continue t...</td>\n",
       "      <td>BOS Mr. Speaker, we have been clear. We contin...</td>\n",
       "      <td>BOS Mr. Speaker, let us talk about the TPPCPTP...</td>\n",
       "      <td>BOS Mr. Speaker, we have been clear. We contin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17430</th>\n",
       "      <td>Mr. Speaker, the trans-Pacific partnership is ...</td>\n",
       "      <td>Mr. Speaker, as the member has said, this is a...</td>\n",
       "      <td>BOS Mr. Speaker, as the member has said, this ...</td>\n",
       "      <td>BOS Mr. Speaker, the trans-Pacific partnership...</td>\n",
       "      <td>BOS Mr. Speaker, as the member has said, this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Q  \\\n",
       "17426  Order, please. Usually I can at least hear the...   \n",
       "17427  Mr. Speaker, today we should be celebrating Ca...   \n",
       "17428  Mr. Speaker, the  \\lineBreak Recent changes to...   \n",
       "17429  Mr. Speaker, let us talk about the TPPCPTPTPP,...   \n",
       "17430  Mr. Speaker, the trans-Pacific partnership is ...   \n",
       "\n",
       "                                                       A  \\\n",
       "17426  Mr. Speaker, we have seen real improvements ov...   \n",
       "17427  Mr. Speaker, I assure my hon. colleague that w...   \n",
       "17428  Mr. Speaker, we are extremely concerned and di...   \n",
       "17429  Mr. Speaker, we have been clear. We continue t...   \n",
       "17430  Mr. Speaker, as the member has said, this is a...   \n",
       "\n",
       "                                            paragraphs_a  \\\n",
       "17426  BOS Mr. Speaker, we have seen real improvement...   \n",
       "17427  BOS Mr. Speaker, I assure my hon. colleague th...   \n",
       "17428  BOS Mr. Speaker, we are extremely concerned an...   \n",
       "17429  BOS Mr. Speaker, we have been clear. We contin...   \n",
       "17430  BOS Mr. Speaker, as the member has said, this ...   \n",
       "\n",
       "                                            paragraphs_b  \\\n",
       "17426  BOS Order, please. Usually I can at least hear...   \n",
       "17427  BOS Mr. Speaker, today we should be celebratin...   \n",
       "17428  BOS Mr. Speaker, the  \\lineBreak Recent change...   \n",
       "17429  BOS Mr. Speaker, let us talk about the TPPCPTP...   \n",
       "17430  BOS Mr. Speaker, the trans-Pacific partnership...   \n",
       "\n",
       "                                                     Q_A  \n",
       "17426  BOS Mr. Speaker, we have seen real improvement...  \n",
       "17427  BOS Mr. Speaker, I assure my hon. colleague th...  \n",
       "17428  BOS Mr. Speaker, we are extremely concerned an...  \n",
       "17429  BOS Mr. Speaker, we have been clear. We contin...  \n",
       "17430  BOS Mr. Speaker, as the member has said, this ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "questions_file = 'context'\n",
    "answers_file = 'answers'\n",
    "vocabulary_file = 'vocabulary_movie'\n",
    "padded_questions_file = 'Padded_context'\n",
    "padded_answers_file = 'Padded_answers'\n",
    "unknown_token = 'something'\n",
    "\n",
    "# vocabulary_size = 7000\n",
    "# max_features = vocabulary_size\n",
    "# maxlen_input = 50\n",
    "# maxlen_output = 50  # cut texts after this number of words\n",
    "\n",
    "print (\"Reading the context data...\")\n",
    "# q = open(questions_file, 'r')\n",
    "questions = df_q_a['Q'].values\n",
    "print (\"Reading the answer data...\")\n",
    "# a = open(answers_file, 'r')\n",
    "answers = df_q_a['A'].values\n",
    "\n",
    "all_q_a = answers + questions\n",
    "print (\"Tokenazing the answers...\")\n",
    "paragraphs_a =  answers #[p for p in answers.split('\\n')]\n",
    "paragraphs_b =  questions # all_q_a #[p for p in all.split('\\n')]\n",
    "paragraphs_a = ['BOS '+p+' EOS' for p in paragraphs_a]\n",
    "paragraphs_b = ['BOS '+p+' EOS' for p in paragraphs_b]\n",
    "\n",
    "# update DF\n",
    "df_q_a['paragraphs_a'] = paragraphs_a\n",
    "df_q_a['paragraphs_b'] = paragraphs_b\n",
    "df_q_a['Q_A'] = df_q_a[['paragraphs_a', 'paragraphs_b']].apply(lambda x: u' '.join(x), axis=1)\n",
    "\n",
    "\n",
    "# paragraphs_b = ' '.join(paragraphs_b)\n",
    "# tokenized_text = paragraphs_b.split()\n",
    "# paragraphs_q = questions #[p for p in questions.split('\\n') ]\n",
    "tokenized_answers = [p.split() for p in paragraphs_a]\n",
    "tokenized_questions = [p.split() for p in paragraphs_b]\n",
    "\n",
    "\n",
    "\n",
    "### Counting the word frequencies:\n",
    "##word_freq = nltk.FreqDist(itertools.chain(tokenized_text))\n",
    "##print (\"Found %d unique words tokens.\" % len(word_freq.items()))\n",
    "##\n",
    "### Getting the most common words and build index_to_word and word_to_index vectors:\n",
    "##vocab = word_freq.most_common(vocabulary_size-1)\n",
    "##\n",
    "### Saving vocabulary:\n",
    "##with open(vocabulary_file, 'w') as v:\n",
    "##    pickle.dump(vocab, v)\n",
    "\n",
    "print(answers[0])\n",
    "print(tokenized_answers[0])\n",
    "print(questions[0])\n",
    "print(tokenized_questions[0])\n",
    "\n",
    "df_q_a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "number of Q and A 17431\n",
      "Found 29048 unique tokens.\n",
      "Using vocabulary of size 10000.\n",
      "X.shape (17431, 100)\n",
      "Y.shape (17431, 100)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0   11   14   13   21   41   87    2 1305   35 6447    1    8\n",
      "  202    6    1  206 3415    2   61   25  904   12]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_words = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 100 \n",
    "\n",
    "# print(u' '.join(str(v) for v in tokenized_questions))\n",
    "\n",
    "print('Loading data...')\n",
    "print('number of Q and A', len(df_q_a))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df_q_a[['Q_A']].apply(lambda x: u' '.join(x))) # fit on Q and A\n",
    "X = tokenizer.texts_to_sequences(u' '.join(v) for v in tokenized_questions)\n",
    "Y = tokenizer.texts_to_sequences(u' '.join(v) for v in tokenized_answers)\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print (\"Using vocabulary of size %d.\" % max_words)\n",
    "\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "Y = pad_sequences(Y, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "\n",
    "print(X[0])\n",
    "\n",
    "# Replacing all words not in our vocabulary with the unknown token:\n",
    "# for i, sent in enumerate(tokenized_answers):\n",
    "#     tokenized_answers[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
    "\n",
    "# for i, sent in enumerate(tokenized_questions):\n",
    "#     tokenized_questions[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
    "\n",
    "# Creating the training data:\n",
    "# X = np.asarray([[word_to_index[w] for w in sent] for sent in tokenized_questions])\n",
    "# Y = np.asarray([[word_to_index[w] for w in sent] for sent in tokenized_answers])\n",
    "\n",
    "# Q = sequence.pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# A = sequence.pad_sequences(Y, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# print(Q[0])\n",
    "# print(A[0])\n",
    "\n",
    "with open(padded_questions_file, 'wb') as q:\n",
    "    pickle.dump(X, q)\n",
    "    \n",
    "with open(padded_answers_file, 'wb') as a:\n",
    "    pickle.dump(Y, a)\n",
    "    \n",
    "    \n",
    "# Important.... print out the X and Y to find the EOS === here its 12\n",
    "EOS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 429693 word vectors.\n",
      "normalizing vectors\n"
     ]
    }
   ],
   "source": [
    "# **********************************************************************\n",
    "# Reading a pre-trained word embedding and addapting to our vocabulary:\n",
    "# **********************************************************************\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open( 'data/vectors.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('normalizing vectors')\n",
    "embedding_matrix = preprocessing.robust_scale(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model of the chatbot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "MAX_SEQUENCE_LENGTH 100\n",
      "max_words 10000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_context (InputLayer)      (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_answer (InputLayer)       (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    (None, 100, 100)     2904900     input_context[0][0]              \n",
      "                                                                 input_answer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encode_context (LSTM)           (None, 300)          481200      shared_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decode_answer (LSTM)            (None, 300)          481200      shared_embedding[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           encode_context[0][0]             \n",
      "                                                                 decode_answer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu_activation (Dense)         (None, 5000)         3005000     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax_activation (Dense)      (None, 10000)        50010000    relu_activation[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 56,882,300\n",
      "Trainable params: 53,977,400\n",
      "Non-trainable params: 2,904,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonic/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence_embedding_size = 300\n",
    "weights_file = 'nothing yet'\n",
    "\n",
    "def init_model():\n",
    "    print(type(X), type(Y)) \n",
    "\n",
    "    input_context = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input_context')\n",
    "    input_answer = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input_answer')\n",
    "\n",
    "    LSTM_encoder = LSTM(sentence_embedding_size, kernel_initializer= 'lecun_uniform', name='encode_context')\n",
    "    LSTM_decoder = LSTM(sentence_embedding_size, kernel_initializer= 'lecun_uniform', name='decode_answer')\n",
    "\n",
    "    if os.path.isfile(weights_file):\n",
    "        Shared_Embedding = Embedding(output_dim=EMBEDDING_DIM, input_dim=max_words, \n",
    "                                     input_length=maxlen_input)\n",
    "    else:\n",
    "    #     Shared_Embedding = Embedding(output_dim=EMBEDDING_DIM, input_dim=max_words, \n",
    "    #                                  weights=[embedding_matrix], input_length=maxlen_input)\n",
    "        Shared_Embedding = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n",
    "                                    weights=[embedding_matrix],\n",
    "                                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False, name='shared_embedding')\n",
    "\n",
    "    print('MAX_SEQUENCE_LENGTH', MAX_SEQUENCE_LENGTH)\n",
    "    print('max_words', max_words)\n",
    "\n",
    "    word_embedding_context = Shared_Embedding(input_context)\n",
    "    context_embedding = LSTM_encoder(word_embedding_context)\n",
    "\n",
    "    word_embedding_answer = Shared_Embedding(input_answer)\n",
    "    answer_embedding = LSTM_decoder(word_embedding_answer)\n",
    "\n",
    "    # merge_layer = Concatenate([context_embedding, answer_embedding], concat_axis=1)\n",
    "    merge_layer = Concatenate(axis=1)([context_embedding, answer_embedding])\n",
    "\n",
    "    out = Dense(int(max_words/2), activation='relu', name='relu_activation')(merge_layer)\n",
    "    out = Dense(max_words, activation='softmax', name='softmax_activation')(out)\n",
    "\n",
    "    model = Model(input=[input_context, input_answer], output = [out])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.00005))\n",
    "\n",
    "    if os.path.isfile(weights_file):\n",
    "        model.load_weights(weights_file)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(17431, 100)\n",
      "<class 'numpy.ndarray'>\n",
      "Number of exemples = 16431\n",
      "qt (1000, 100) q (16430, 100)\n",
      "at (1000, 100) a (16430, 100)\n",
      "step 1643 round_exem 16430\n"
     ]
    }
   ],
   "source": [
    "# ************************************************************************\n",
    "# Loading the data:\n",
    "# ************************************************************************\n",
    "n_test = 1000\n",
    "num_subsets = 10\n",
    "\n",
    "q = X #cPickle.load(open(questions_file, 'rb'))\n",
    "a = Y #cPickle.load(open(answers_file, 'rb'))\n",
    "\n",
    "print(type(q))\n",
    "print(a.shape)\n",
    "# n_exem, n_words = a.shape\n",
    "n_exem = a.shape[0]\n",
    "\n",
    "qt = q[0:n_test,:]\n",
    "at = a[0:n_test,:]\n",
    "q = q[n_test + 1:,:]\n",
    "a = a[n_test + 1:,:]\n",
    "\n",
    "print(type(q))\n",
    "\n",
    "print('Number of exemples = %d'%(n_exem - n_test))\n",
    "print('qt', qt.shape, 'q', q.shape)\n",
    "print('at', at.shape, 'a', a.shape)\n",
    "step = int(np.around((n_exem - n_test)/num_subsets))\n",
    "round_exem = int(step * num_subsets)\n",
    "print('step', step, 'round_exem', round_exem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "Epochs = 100\n",
    "BatchSize = 128  #  Check the capacity of your GPU\n",
    "Patience = 0\n",
    "dropout = .25\n",
    "n_test = 100\n",
    "\n",
    "print(type(q))\n",
    "q2 = q[0:step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16430 1643\n",
      "n 0\n",
      "113157\n",
      "Training epoch: 0, training examples: 0 - 1643\n",
      "Epoch 1/1\n",
      " 43008/113157 [==========>...................] - ETA: 45:41 - loss: 6.4556"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-da62cf71272d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training epoch: %d, training examples: %d - %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# *************************************************************************\n",
    "# Bot training:\n",
    "# *************************************************************************\n",
    "print(round_exem, step)\n",
    "\n",
    "x = range(0,Epochs) \n",
    "valid_loss = np.zeros(Epochs)\n",
    "train_loss = np.zeros(Epochs)\n",
    "for m in range(Epochs):\n",
    "    \n",
    "    # Loop over training batches due to memory constraints:\n",
    "    for n in range(0,round_exem,step):\n",
    "        print('n', n)\n",
    "        \n",
    "        q2 = q[n:n+step]\n",
    "        s = q2.shape\n",
    "        count = 0\n",
    "        for i, sent in enumerate(a[n:n+step]):\n",
    "            l = np.where(sent==EOS)  #  the position od the symbol EOS\n",
    "            limit = l[0][0]\n",
    "            count += limit + 1\n",
    "            \n",
    "        print(count)\n",
    "        Q = np.zeros((count,MAX_SEQUENCE_LENGTH))\n",
    "        A = np.zeros((count,MAX_SEQUENCE_LENGTH))\n",
    "        Y = np.zeros((count,max_words))\n",
    "        \n",
    "        # Loop over the training examples:\n",
    "        count = 0\n",
    "        for i, sent in enumerate(a[n:n+step]):\n",
    "            ans_partial = np.zeros((1,MAX_SEQUENCE_LENGTH))\n",
    "            \n",
    "            # Loop over the positions of the current target output (the current output sequence):\n",
    "            l = np.where(sent==EOS)  #  the position of the symbol EOS\n",
    "            limit = l[0][0]\n",
    "\n",
    "            for k in range(1,limit+1):\n",
    "                # Mapping the target output (the next output word) for one-hot codding:\n",
    "                y = np.zeros((1, max_words))\n",
    "                y[0, sent[k]] = 1\n",
    "\n",
    "                # preparing the partial answer to input:\n",
    "\n",
    "                ans_partial[0,-k:] = sent[0:k]\n",
    "\n",
    "                # training the model for one epoch using teacher forcing:\n",
    "                \n",
    "                Q[count, :] = q2[i:i+1] \n",
    "                A[count, :] = ans_partial \n",
    "                Y[count, :] = y\n",
    "                count += 1\n",
    "                \n",
    "        print('Training epoch: %d, training examples: %d - %d'%(m,n, n + step))\n",
    "        model.fit([Q, A], Y, batch_size=BatchSize, epochs=1, verbose=2)\n",
    "         \n",
    "        test_input = qt[41:42]\n",
    "        print(print_result(test_input))\n",
    "        train_input = q[41:42]\n",
    "        print(print_result(train_input))        \n",
    "        \n",
    "    model.save_weights(weights_file, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
