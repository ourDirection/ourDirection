{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Takes as input a dialogue file and creates a processed version of it.\n",
    "If given an external dictionary, the input dialogue file will be converted\n",
    "using that input dictionary.\n",
    "\n",
    "@author Alessandro Sordoni, Iulian Vlad Serban\n",
    "\"\"\"\n",
    "\n",
    "import collections\n",
    "import numpy\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('text2dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>SubjectOfBusinessTitle</th>\n",
       "      <th>FloorLanguage</th>\n",
       "      <th>date</th>\n",
       "      <th>personSpeaking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27367</th>\n",
       "      <td>27367</td>\n",
       "      <td>27367</td>\n",
       "      <td>BOS Mr. Speaker, yesterday, an American giant ...</td>\n",
       "      <td>BOS Mr. Speaker, I would like to thank the hon...</td>\n",
       "      <td>International Trade</td>\n",
       "      <td>FR</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>Ms. Brigitte Sansoucy (Saint-Hyacinthe—Bagot, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27368</th>\n",
       "      <td>27368</td>\n",
       "      <td>27368</td>\n",
       "      <td>BOS Mr. Speaker, the government has agreed to ...</td>\n",
       "      <td>BOS Mr. Speaker, that could not be further fro...</td>\n",
       "      <td>Employment Insurance</td>\n",
       "      <td>FR</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>Hon. Stéphane Dion (Saint-Laurent—Cartierville...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27369</th>\n",
       "      <td>27369</td>\n",
       "      <td>27369</td>\n",
       "      <td>BOS Mr. Speaker, while SMEs like the businesse...</td>\n",
       "      <td>BOS Mr. Speaker, we know that it is very impor...</td>\n",
       "      <td>Taxation</td>\n",
       "      <td>FR</td>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>Mr. Alexandre Boulerice (Rosemont—La Petite-Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27370</th>\n",
       "      <td>27370</td>\n",
       "      <td>27370</td>\n",
       "      <td>BOS Mr. Speaker, as researcher Alain Deneault ...</td>\n",
       "      <td>BOS Mr. Speaker, our government is committed t...</td>\n",
       "      <td>Taxation</td>\n",
       "      <td>FR</td>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>Hon. Bill Morneau (Minister of Finance, Lib.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27371</th>\n",
       "      <td>27371</td>\n",
       "      <td>27371</td>\n",
       "      <td>BOS Mr. Speaker, Canadians are tired of the cu...</td>\n",
       "      <td>BOS Mr. Speaker, I was very pleased last year ...</td>\n",
       "      <td>Government Accountability</td>\n",
       "      <td>EN</td>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>Ms. Cheryl Hardcastle (Windsor—Tecumseh, NDP)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  \\\n",
       "27367       27367         27367   \n",
       "27368       27368         27368   \n",
       "27369       27369         27369   \n",
       "27370       27370         27370   \n",
       "27371       27371         27371   \n",
       "\n",
       "                                                       Q  \\\n",
       "27367  BOS Mr. Speaker, yesterday, an American giant ...   \n",
       "27368  BOS Mr. Speaker, the government has agreed to ...   \n",
       "27369  BOS Mr. Speaker, while SMEs like the businesse...   \n",
       "27370  BOS Mr. Speaker, as researcher Alain Deneault ...   \n",
       "27371  BOS Mr. Speaker, Canadians are tired of the cu...   \n",
       "\n",
       "                                                       A  \\\n",
       "27367  BOS Mr. Speaker, I would like to thank the hon...   \n",
       "27368  BOS Mr. Speaker, that could not be further fro...   \n",
       "27369  BOS Mr. Speaker, we know that it is very impor...   \n",
       "27370  BOS Mr. Speaker, our government is committed t...   \n",
       "27371  BOS Mr. Speaker, I was very pleased last year ...   \n",
       "\n",
       "          SubjectOfBusinessTitle FloorLanguage        date  \\\n",
       "27367        International Trade            FR  2016-02-04   \n",
       "27368       Employment Insurance            FR  2013-02-01   \n",
       "27369                   Taxation            FR  2017-02-24   \n",
       "27370                   Taxation            FR  2017-02-24   \n",
       "27371  Government Accountability            EN  2017-02-24   \n",
       "\n",
       "                                          personSpeaking  \n",
       "27367  Ms. Brigitte Sansoucy (Saint-Hyacinthe—Bagot, ...  \n",
       "27368  Hon. Stéphane Dion (Saint-Laurent—Cartierville...  \n",
       "27369  Mr. Alexandre Boulerice (Rosemont—La Petite-Pa...  \n",
       "27370      Hon. Bill Morneau (Minister of Finance, Lib.)  \n",
       "27371      Ms. Cheryl Hardcastle (Windsor—Tecumseh, NDP)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_df = pd.read_csv('../../minerva/data/q_a_all.csv')\n",
    "\n",
    "\n",
    "#\"Dialogue file; assumed shuffled with one document \n",
    "# (e.g. one movie dialogue, or one Twitter conversation or one Ubuntu conversation) per line\")\n",
    "\n",
    "\n",
    "train = q_a_df.iloc[:25000]\n",
    "validation = q_a_df.iloc[25000:26000]\n",
    "test = q_a_df.iloc[26000:]\n",
    "\n",
    "input_list = {'data/Q_A_dataset.txt': q_a_df,\n",
    "              'data/Q_A_train.txt': train,\n",
    "              'data/Q_A_validation.txt': validation,\n",
    "              'data/Q_A_test.txt': test}\n",
    "\n",
    "\n",
    "def write_file(df):\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Q'].strip() + ' </s> ' + row['A'].strip()\n",
    "        if text != '':\n",
    "            file.write(text + '\\n')\n",
    "\n",
    "for dialogue_file, df in input_list.items():\n",
    "    with open(dialogue_file, 'w') as file:\n",
    "        write_file(df)\n",
    "\n",
    "    \n",
    "q_a_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_pickle(obj, filename):\n",
    "    if os.path.isfile(filename):\n",
    "        logger.info(\"Overwriting %s.\" % filename)\n",
    "    else:\n",
    "        logger.info(\"Saving to %s.\" % filename)\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# \"Vocabulary cutoff (optional)\")\n",
    "cutoff = 1000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "unk = \"<unk>\"\n",
    "\n",
    "###############################\n",
    "# Part I: Create the dictionary\n",
    "###############################\n",
    "def load_dict(dict_file):\n",
    "    # Load external dictionary\n",
    "    assert os.path.isfile(dict_file)\n",
    "    vocab = dict([(x[0], x[1]) for x in pickle.load(open(dict_file, \"rb\"))])\n",
    "    \n",
    "    # Check consistency\n",
    "    assert '<unk>' in vocab\n",
    "    assert '</s>' in vocab\n",
    "    assert '</d>' in vocab\n",
    "\n",
    "    # Also check special tags, which must exist in the Movie-Scriptolog dataset\n",
    "    assert '<first_speaker>' in vocab\n",
    "    assert '<second_speaker>' in vocab\n",
    "    assert '<third_speaker>' in vocab\n",
    "    assert '<minor_speaker>' in vocab\n",
    "    assert '<voice_over>' in vocab\n",
    "    assert '<off_screen>' in vocab\n",
    "    assert '<pause>' in vocab\n",
    "    \n",
    "#     return vocab\n",
    "\n",
    "def create_vocab(input_file):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    for line in open(input_file, 'r'):\n",
    "        line_words = line.strip().split()\n",
    "        \n",
    "        if len(line_words) == 0:\n",
    "            continue\n",
    "            \n",
    "        if line_words[len(line_words)-1] != '</s>':\n",
    "            line_words.append('</s>')\n",
    "\n",
    "        s = [x for x in line_words]\n",
    "        word_counter.update(s) \n",
    "\n",
    "    total_freq = sum(word_counter.values())\n",
    "    logger.info(\"Total word frequency in dictionary %d \" % total_freq) \n",
    "\n",
    "    if cutoff != -1:\n",
    "        logger.info(\"Cutoff %d\" % cutoff)\n",
    "        vocab_count = word_counter.most_common(cutoff)\n",
    "    else:\n",
    "        vocab_count = word_counter.most_common()\n",
    "\n",
    "    # Add special tokens to the vocabulary\n",
    "    vocab = {'<unk>': 0, '</s>': 1, '</d>': 2, \n",
    "             '<first_speaker>': 3, '<second_speaker>': 4, \n",
    "             '<third_speaker>': 5, '<minor_speaker>': 6, \n",
    "             '<voice_over>': 7, '<off_screen>': 8, '<pause>': 9}\n",
    "\n",
    "    # Add other tokens to vocabulary in the order of their frequency\n",
    "    i = 10\n",
    "    for (word, count) in vocab_count:\n",
    "        if not word in vocab:\n",
    "            vocab[word] = i\n",
    "            i += 1\n",
    "            \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Part II: Binarize the dialogues\n",
    "#################################\n",
    "\n",
    "def create_dict(input_file, output):\n",
    "    # Create vocab\n",
    "    vocab = create_vocab(input_file)\n",
    "    logger.info(\"Vocab size %d\" % len(vocab))\n",
    "\n",
    "\n",
    "    # Everything is loaded into memory for the moment\n",
    "    binarized_corpus = []\n",
    "    # Some statistics\n",
    "    unknowns = 0.\n",
    "    num_terms = 0.\n",
    "    freqs = collections.defaultdict(lambda: 0)\n",
    "\n",
    "    # counts the number of dialogues each unique word exists in; also known as document frequency\n",
    "    df = collections.defaultdict(lambda: 0)\n",
    "\n",
    "    for line, dialogue in enumerate(open(input_file, 'r')):\n",
    "        dialogue_words = dialogue.strip().split()\n",
    "        if len(dialogue_words) == 0:\n",
    "            continue\n",
    "\n",
    "        if dialogue_words[len(dialogue_words)-1] != '</s>':\n",
    "            dialogue_words.append('</s>')\n",
    "\n",
    "        # Convert words to token ids and compute some statistics\n",
    "        dialogue_word_ids = []\n",
    "        for word in dialogue_words:\n",
    "            word_id = vocab.get(word, 0)\n",
    "            dialogue_word_ids.append(word_id)\n",
    "            unknowns += 1 * (word_id == 0)\n",
    "            freqs[word_id] += 1\n",
    "\n",
    "        num_terms += len(dialogue_words)\n",
    "\n",
    "        # Compute document frequency statistics\n",
    "        unique_word_indices = set(dialogue_word_ids)\n",
    "        for word_id in unique_word_indices:\n",
    "            df[word_id] += 1\n",
    "\n",
    "        # Add dialogue to corpus\n",
    "        binarized_corpus.append(dialogue_word_ids)\n",
    "\n",
    "    safe_pickle(binarized_corpus, \"data/%s.dialogues.pkl\" % output)\n",
    "\n",
    "    if dict_file == '':\n",
    "         safe_pickle([(word, word_id, freqs[word_id], df[word_id]) for word, word_id in vocab.items()], \n",
    "                     'data/%s.dict.pkl' % output)\n",
    "\n",
    "    logger.info(\"Number of unknowns %d\" % unknowns)\n",
    "    logger.info(\"Number of terms %d\" % num_terms)\n",
    "    logger.info(\"Mean document length %f\" % float(sum(map(len, binarized_corpus))/len(binarized_corpus)))\n",
    "    logger.info(\"Writing training %d dialogues (%d left out)\" % (len(binarized_corpus), line + 1 - len(binarized_corpus)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:text2dict:Total word frequency in dictionary 5317375 \n",
      "INFO:text2dict:Cutoff 1000\n",
      "INFO:text2dict:Vocab size 1009\n",
      "INFO:text2dict:Overwriting data/dataset.dialogues.pkl.\n",
      "INFO:text2dict:Overwriting data/dataset.dict.pkl.\n",
      "INFO:text2dict:Number of unknowns 1158506\n",
      "INFO:text2dict:Number of terms 5317375\n",
      "INFO:text2dict:Mean document length 184.464546\n",
      "INFO:text2dict:Writing training 28826 dialogues (329 left out)\n",
      "INFO:text2dict:Total word frequency in dictionary 260807 \n",
      "INFO:text2dict:Cutoff 1000\n",
      "INFO:text2dict:Vocab size 1009\n",
      "INFO:text2dict:Overwriting data/test.dialogues.pkl.\n",
      "INFO:text2dict:Overwriting data/test.dict.pkl.\n",
      "INFO:text2dict:Number of unknowns 55372\n",
      "INFO:text2dict:Number of terms 260807\n",
      "INFO:text2dict:Mean document length 175.155809\n",
      "INFO:text2dict:Writing training 1489 dialogues (25 left out)\n",
      "INFO:text2dict:Total word frequency in dictionary 191334 \n",
      "INFO:text2dict:Cutoff 1000\n",
      "INFO:text2dict:Vocab size 1009\n",
      "INFO:text2dict:Overwriting data/validation.dialogues.pkl.\n",
      "INFO:text2dict:Overwriting data/validation.dict.pkl.\n",
      "INFO:text2dict:Number of unknowns 41038\n",
      "INFO:text2dict:Number of terms 191334\n",
      "INFO:text2dict:Mean document length 180.844991\n",
      "INFO:text2dict:Writing training 1058 dialogues (39 left out)\n",
      "INFO:text2dict:Total word frequency in dictionary 4865234 \n",
      "INFO:text2dict:Cutoff 1000\n",
      "INFO:text2dict:Vocab size 1009\n",
      "INFO:text2dict:Overwriting data/train.dialogues.pkl.\n",
      "INFO:text2dict:Overwriting data/train.dict.pkl.\n",
      "INFO:text2dict:Number of unknowns 1060443\n",
      "INFO:text2dict:Number of terms 4865234\n",
      "INFO:text2dict:Mean document length 185.137715\n",
      "INFO:text2dict:Writing training 26279 dialogues (265 left out)\n"
     ]
    }
   ],
   "source": [
    "# python convert-text2dict.py <training_file> --cutoff <vocabulary_size> Training \n",
    "# python convert-text2dict.py <validation_file> --dict=Training.dict.pkl Validation \n",
    "# python convert-text2dict.py <test_file> --dict=Training.dict.pkl <vocabulary_size> Test\n",
    "\n",
    "# # \"Prefix of the pickle binarized dialogue corpus\")\n",
    "# output = 'data/'\n",
    "\n",
    "\n",
    "# \"External dictionary (pkl file)\")\n",
    "dict_file = ''\n",
    "\n",
    "input_list = {'data/Q_A_dataset.txt': 'dataset',\n",
    "              'data/Q_A_train.txt': 'train',\n",
    "              'data/Q_A_validation.txt': 'validation',\n",
    "              'data/Q_A_test.txt': 'test'}\n",
    "\n",
    "\n",
    "for dialogue_file, output in input_list.items():\n",
    "    create_dict(dialogue_file, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dict('data/train.dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
